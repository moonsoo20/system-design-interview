2장 개략적인 규모 추정
===========

개략적인 규모 추정은 *2의 제곱수*나 *latency*값, *가용성에 관계돈 수치*를 잘 이해하는 것이 중요하다.
<br/>

# 2의 제곱수
| 근사치                 | 축약형 | 2의 x 제곱  |
|:--------------------|:---:|:--------:|
| 천(thousand)         | 1KB | 2<sup>10 | 
| 백만(milion)          | 1MB | 2<sup>20 | 
| 10억(bilion)         | 1GB | 2<sup>30 | 
| 1조(trillion)        | 1TB | 2<sup>40 | 
 | 1000조(quadrilliion) | 1PB | 2<sup>50 | 

<br>

# 모든 프로그래머가 알아야 하는 latency 값


| 연산명      | 시간 |
|:--------------------|:---:|
| L1 캐시 참조 | 0.5ns  |
| 분기 예측 오류 | 5ns |
| L2 캐시 참조 | 7ns | 
| 뮤텍스 락/언락 | 100ns |  
| 주 메모리 참조 | 100ns | 
| Zippy로 1KB 압축 | 10,000ns = 10μs |
| 1Gbps 네트워크로 2KB 전송 | 20,000ns = 20μs |
| 메모리에서 1MB 순차적으로 read | 250,000ns = 250μs |
| 같은 데이터 센터 내에서의 메시지 왕복 지연시간 | 500,000ns = 500μs |
| 디스크 탐색 | 10,000,000ns = 10ms |
| 네트워크에서 1MB 순차적으로 read | 10,000,000ns = 10ms |
| 디스크에서 1MB 순차적으로 read | 30,000,000ns = 30ms |
| 한 패킷의 CA로부터 네덜란드까지의 왕복 latency | 150,000,000ns = 150ms |

## 결론
- 메모리는 빠르지만 디스크는 느리다.
- 디스크 탐색(seek)은 피하자.
- 단순 압축 알고리즘은 빠르다
- 인터넷 전송하기 전 압축할 것
- 데이터 센터는 여러 지역에 분산되어 있고 센터들 간에 데이터를 주고받는 데는 시간이 걸린다.   



# 요약
- 근사치를 활용하여 계산하자.
- 가정을 적어두라.
- 단위를 붙여라.

<br>

***
<br>

4장 처리율 제한 장치의 설계
===

네트워크 시스템에서 rate limiter는 클라이언트 혹은 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.
HTTP의 경우 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.   
서버가 특정 임계치까지 클라이언트 요청을 허용하는 것이다.   

처리율 제한 장치는 다음과 같은 특징이 있다.
- DoS 공격으로 인한 resource starvation 방지한다.
- 비용 절감
- 서버 과부하를 막는다.

처리율 제한 장치는 클라이언트 요청을 쉽게 위변조 할수 있으므로 **서버 측**에 두는 것이 좋다.   
혹은 처리율 제한 미들웨어를 만들어 통제하는 방법도 있다.   

## 처리율 제한 알고리즘
### 토큰 버킷 알고리즘
폭 넓게 이용되는 알고리즘이다. 간단하고 세간의 이해도가 높으며 인터넷 기업들이 보편적으로 사용하고 있다.
- 토큰 버킷은 지정된 용량을 갖는 컨테이너다. 버킷에는 사전 설정된 양의 토큰이 채워진다.   
- 토큰 공급기(refiller)는 버킷을 추가하고,  refiller에 버킷이 가득 차면 overflow.
- 각 요청은 처리될 떄마다 토큰이 소비된다.
- 토큰이 있는 경우, 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다.
- 토큰이 없는 경우, 해당 요청은 dropped
   
<br>

![img](https://www.researchgate.net/profile/Amir-Varasteh-2/publication/351452059/figure/fig1/AS:1021892089618432@1620649468202/Diagram-representing-token-bucket-algorithm.png)

>#### 장점
> - 구현이 쉽다.
> - 메모리 사용 측면에서도 효율적이다.
> - burst of traffic 처리 가능. (단, 버킷에 남은 토큰이 있을 경우)

>#### 단점
> - *버킷 크기*와 *토큰 공급률(refill rate)* 2개의 파라미터를 가지고 있는데, 적절하게 튜닝하는 것이 까다롭다.   

### 누출 버킷 알고리즘 (leaky bucket)
토큰 버킷 알고리즘과 비슷하지만 **요청 처리율(refill rate)이 고정되어있다**는 점이 다르다.   
보통 FIFO 큐로 구현한다.
- 요청이 오면, 큐가 차있는지 확인한다. 
- 빈 자리가 있을 경우에 큐에 새 요청을 추가한다.
- 큐가 가득 차 있는 경우에는 새 요청을 버린다.
- 지정된 시간마다 큐에서 요청을 꺼낸다.

누출 버킷 알고리즘은 **버킷 크기**(큐 사이즈)와 **처리율(rate filler)** 2개의 파라미터를 사용한다.   
<br>
**버킷 크기(큐)** 에는 처리할 항목들이,   
**처리율**에는 지정된 시간 당 몇 개의 항목을 처리할 지 정하며 초 단위로 표현한다.
<br>
<br>

![img](https://media.geeksforgeeks.org/wp-content/uploads/leakyTap-1.png)
<br>
#### 장점
> - 큐의 크기가 제한되어 있어서 메모리 사용량 측면에서 효율적
> - fixed rate를 가지고 있어서 안정적 출력이 필요한 경우가 적합하다.
<br>

#### 단점
> - 위의 그림처럼, 단시간 트래픽이 몰릴 경우, 오랜 요청이 쌓여 최신 요청이 버려진다.
> - 토큰 버킷과 마찬가지로 2개의 파라미터를 올바르게 튜닝하기 어렵다.

<br>

### 고정 윈도 카운터 알고리즘 (Fixed Window Counter)
고정 윈도 카운터 알고리즘은 *타임라인*을 **fixed window**로 나누고 각 *윈도우*마다 **카운터**를 붙인다.   
요청이 접수될 때마다 카운터는 1씩 증가하며 임계치(threshold)에 도달하면 **윈도우**가 새로 열릴떄 까지 **버려진다**.
<br>

![img](https://res.cloudinary.com/practicaldev/image/fetch/s--DnnLwiI7--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/i45cox7md3dt9h7t2syf.png)
<br>

해당 알고리즘의 **문제**는 **윈도 경계 부근에 트래픽이 집중될 경우** 할당량보다 더 많은 요청이 처리될 수 있다.
<br>
#### 장점
> - 메모리 효율에 좋다.
> - 이해하기 쉽다.
> - 윈도가 닫히는 시점에 카운터를 초기화 하는 방식으로 트래픽 패턴 처리에 용이

#### 단점
> - 윈도 경계 부근에서 트래픽이 몰릴 경우, 시스템 처리 한도보다 요청을 많이 처리하게 된다.

<br>

### 이동 윈도 로깅 알고리즘 (Sliding Window Logging)
고정 윈도 카운터 알고리즘의 단점을 해결할 수 있는 알고리즘이다.
<br>
- 요청의 타임 스탬프를 추적한다.
- 요청이 오면, 만료된 타임 스탬프는 제거한다.
- 새 요청의 타임 스탬프를 로그에 추가한다.
- 로그의 크기 $\leq$ 허용치 : 요청을 시스템에 전달한다.
- 로그의 크기 > 허용치 : 처리 거부

<br>

#### 장점
> - 처리율 제한 메커니즘이 정교하다.

#### 단점
> - 거부된 요청의 타임 스탬프도 갖고 있어 다량의 메모리를 사용한다.

<br>

### 이동 윈도 카운터 알고리즘 (Sliding Window Counter)
고정 윈도 카운터 + 이동 윈도 로깅 알고리즘을 결합한 것이다.   
<br>
#### 장점
> - 이전 시간대의 평균 처리율에 따라 현재 윈도 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 대응 가능
> - 메모리 효율이 좋다.

<br>

#### 단점
> - 직전 시간대의 요청이 균등하다는 가정 하에 계산하기 때문에 느슨하다.   
> 그러나 버려진 요청은 극히 드물기 때문에 심각한 문제는 아니다.

<br>

## 개략적인 아키텍처
처리율 제한 알고리즘의 아이디어는 단순하다. 요청을 추적할 수 있는 **카운터**를 추적 대상별로 둔다.   
그리고  카운터 값을 넘어 갔을 때 도착한 요청은 거부되는 것이다.
<br>
카운터는 *캐시*에 저장하는 것이 바람직하다. 만료 정책을 지원하기 떄문이다.
<br>

***

## 처리율 제한 규칙
보통 configuration 파일 형태로 디스크에 저장된다.
<br>

## 처리율한도 초과 트래픽의 처리
HTTP 응답 헤더에는 *요청이 처리율 제한에 걸리고 있는가(throttle)*, *어떻게 감지하는가*, *처리율 제한 걸리기 까지 보낼 수 있는 요청의 수* 등을 알 수 있다.

<br>

## 분산 환경에서의 처리율 제한 장치의 구현
### 경쟁 조건 (Race Condition)
병행성이 심한 환경에서는 경쟁 조건이 나타날 수 있다.   
서로 다른 요청을 처리하는 스레드에서 병렬로 counter를 증가할 경우이다.
<br>
두 병렬 스레드는 요청을 처리할 때, counter를 공유하지 않으므로 증가하지 않고 같은 값을 나타낼 수 있다.
<br>
이는 **락(Lock)**으로 해결할 수 있다. 그러나, 시스템 성능을 저하시키기 때문에 **루아 스크립트**나 **정렬 집합(레디스 자료구조)**
를 사용하여 해결할 수 있다.
<br>
<br>
### 동기화 이휴
처리율 제한 장치를 여러대 둘 때 동기화를 잘 해야할 것이다. 고정 세션으로 해결할 수 있지만 확장성에 좋지 않기 때문이다. 따라서 레디스나 중앙 집중형 데이터 저장소를 쓰는 것이 좋다.
<br><br>
### 성능 최적화
- 데이터 센터 외의 edge server를 두어 지연시간을 줄인다.
- 제한 장치 간에 데이터 동기화 시 최종 일관성 모델(Eventual Consistency Model)을 사용한다.

<br><br>
### 모니터링
처리율 제한 알고리즘이 효과적인지, 처리율 제한 규칙이 효과적인지 파악한다.
<br><br>
## 요약
- 토큰 버킷, 누출 버킷, 고정 윈도 카운터, 이동 윈도 로그, 이동 윈도 카운터 알고리즘
- limit을 fixed하게 하는가, flexible하게 하는가에 대한 hard, soft 처리율 제한
- 처리율 제한을 회피하는 방법 :
  - **클라이언트 캐시**를 사용하여 **API 호출 횟수**를 줄인다.
  - limit을 파악한다.
  - 에러 처리를 통해 예외를 복구시킬 수 있도록 한다.
  - retry 로직을 구현할 때는 충분한 back-off 시간을 둔다.

<br><br>









# 링크
- Image 참조
  - [토큰 버킷 알고리즘](https://www.researchgate.net/figure/Diagram-representing-token-bucket-algorithm_fig1_351452059)
  - [누출 버킷 알고리즘](https://www.geeksforgeeks.org/leaky-bucket-algorithm/)
  - [고정 윈도 카운터 알고리즘](https://dev.to/satrobit/rate-limiting-using-the-fixed-window-algorithm-2hgm)

  <br>
  
- 참조
    - Alex Xu, (2021). 가상 면접 사례로 배우는 대규모 시스템 설계 기초, 인사이트


